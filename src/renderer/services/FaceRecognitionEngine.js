// üöÄ MOTEUR DE RECONNAISSANCE FACIALE ULTRA-PERFORMANT
// Syst√®me complet et fonctionnel pour la d√©tection et reconnaissance de visages

import * as faceapi from 'face-api.js';
// import faceVectorIndex from './FaceVectorIndex'; // Ne pas utiliser c√¥t√© renderer

class FaceRecognitionEngine {
  constructor() {
    this.isInitialized = false;
    this.modelsLoaded = false;
    this.detectionNet = null;
    this.recognitionNet = null;
    this.landmarkNet = null;
    this.ageGenderNet = null;
    this.expressionNet = null;
    
    // Configuration optimis√©e pour recherche ultra-pr√©cise
    this.config = {
      // D√©tection standard
      detectionThreshold: 0.3,
      minFaceSize: 15,
      scaleFactor: 0.8,
      
      // Reconnaissance √©quilibr√©e
      similarityThreshold: 0.4,
      maxResults: 100,
      
      // Performance standard
      inputSize: 416,
      scoreThreshold: 0.3,
      
      // Qualit√© standard
      minDescriptorQuality: 0.2,
      confidenceThreshold: 0.4,
      
      // Param√®tres pour petits visages
      enableMultiScaleDetection: true,
      maxScales: 4,
      scaleStep: 0.75,
      
      // Param√®tres pour visages de faible qualit√©
      enableBlurDetection: true,
      enablePartialFaceDetection: true,
      enableOccludedFaceDetection: true,
      
      // Param√®tres de recherche standard
      enableDescriptorAugmentation: true,
      
      // Param√®tres de base
      minLandmarkConfidence: 0.5,
      minFaceArea: 800,
      maxBlurScore: 0.8,
      minVisibleLandmarks: 0.6
    };
    
    // Cache pour optimiser les performances
    this.descriptorCache = new Map();
    this.analysisCache = new Map();
    
    console.log('üéØ Moteur de reconnaissance faciale initialis√©');
  }

  // üöÄ INITIALISATION DES MOD√àLES
  async initialize() {
    try {
      console.log('üöÄ Initialisation du moteur de reconnaissance faciale...');

      // Essayer plusieurs ports pour le serveur de mod√®les
      const ports = [3001, 3002, 3003];
      let modelPath = null;
      
      for (const port of ports) {
        try {
          const testUrl = `http://127.0.0.1:${port}/tiny_face_detector/tiny_face_detector_model-weights_manifest.json`;
          console.log(`üîç Test du port ${port}...`);
          
          const response = await fetch(testUrl);
          if (response.ok) {
            modelPath = `http://127.0.0.1:${port}`;
            console.log(`‚úÖ Port ${port} fonctionne, utilisation de: ${modelPath}`);
            break;
          }
        } catch (error) {
          console.log(`‚ùå Port ${port} non disponible`);
        }
      }
      
      if (!modelPath) {
        throw new Error('Aucun serveur de mod√®les disponible');
      }

      console.log('üìÅ Chargement des mod√®les depuis:', modelPath);

      // Charger les mod√®les dans l'ordre
      console.log('üì¶ Chargement du d√©tecteur de visages...');
      await faceapi.nets.tinyFaceDetector.loadFromUri(modelPath + '/tiny_face_detector');
      
      console.log('üì¶ Chargement du mod√®le de landmarks...');
      await faceapi.nets.faceLandmark68Net.loadFromUri(modelPath + '/face_landmark_68');
      
      console.log('üì¶ Chargement du mod√®le de reconnaissance...');
      await faceapi.nets.faceRecognitionNet.loadFromUri(modelPath + '/face_recognition');
      
      console.log('üì¶ Chargement du mod√®le d\'expressions...');
      await faceapi.nets.faceExpressionNet.loadFromUri(modelPath + '/face_expression');
      
      console.log('üì¶ Chargement du mod√®le √¢ge/genre...');
      await faceapi.nets.ageGenderNet.loadFromUri(modelPath + '/age_gender_model');

      this.isInitialized = true;
      this.modelsLoaded = true;

      console.log('‚úÖ Moteur de reconnaissance faciale initialis√© avec succ√®s');
      return true;
    } catch (error) {
      console.error('‚ùå Erreur lors de l\'initialisation:', error);
      throw new Error(`√âchec de l'initialisation: ${error.message}`);
    }
  }

  // üîç D√âTECTION ULTRA-SENSIBLE DE VISAGES
  async detectFaces(imageElement, options = {}) {
    if (!this.isInitialized) {
      throw new Error('Moteur non initialis√©');
    }

    try {
      const config = { ...this.config, ...options };
      console.log('üîç D√©but de la d√©tection des visages...');
      
      let allDetections = [];
      
      // D√©tection multi-√©chelle si activ√©e
      if (config.enableMultiScaleDetection) {
        console.log('üìè D√©tection multi-√©chelle activ√©e');
        
        const scales = [];
        let currentScale = 1.0;
        for (let i = 0; i < config.maxScales; i++) {
          scales.push(currentScale);
          currentScale *= config.scaleStep;
        }
        
        for (const scale of scales) {
          const scaledSize = {
            width: Math.round(imageElement.width * scale),
            height: Math.round(imageElement.height * scale)
          };
          
          console.log(`üîç Analyse √† l'√©chelle ${scale.toFixed(2)} (${scaledSize.width}x${scaledSize.height})`);
          
            const detectorOptions = new faceapi.TinyFaceDetectorOptions({
            inputSize: config.inputSize,
            scoreThreshold: config.scoreThreshold
            });
            
          const detections = await faceapi.detectAllFaces(imageElement, detectorOptions)
            .withFaceLandmarks(true) // Force l'utilisation du mod√®le complet
              .withFaceDescriptors()
              .withAgeAndGender()
              .withFaceExpressions();
            
          if (detections && detections.length > 0) {
            // Ajouter l'√©chelle aux d√©tections
            detections.forEach(d => {
              d.scale = scale;
            // Ajuster les coordonn√©es selon l'√©chelle
              if (scale !== 1.0) {
                d.box = new faceapi.Box({
                  x: d.box.x / scale,
                  y: d.box.y / scale,
                  width: d.box.width / scale,
                  height: d.box.height / scale
                });
                // Ajuster les positions des landmarks
                d.landmarks.positions = d.landmarks.positions.map(p => ({
                  x: p.x / scale,
                  y: p.y / scale
            }));
              }
            });
            allDetections.push(...detections);
          }
        }
      } else {
        console.log('üìè D√©tection standard');
        const detectorOptions = new faceapi.TinyFaceDetectorOptions({
          inputSize: config.inputSize,
          scoreThreshold: config.scoreThreshold
        });
        
        allDetections = await faceapi.detectAllFaces(imageElement, detectorOptions)
          .withFaceLandmarks(true) // Force l'utilisation du mod√®le complet
          .withFaceDescriptors()
          .withAgeAndGender()
          .withFaceExpressions();
      }
      
      // Supprimer les doublons et filtrer par qualit√©
      const uniqueDetections = this.removeDuplicateDetections(allDetections);
      console.log(`üìä ${uniqueDetections.length} visage(s) unique(s) apr√®s suppression des doublons`);
      
      const analyzedFaces = [];
      
      for (let i = 0; i < uniqueDetections.length; i++) {
        const detection = uniqueDetections[i];
        
        console.log(`üîç Analyse du visage ${i + 1}/${uniqueDetections.length}...`);
        
        // V√©rifier la taille minimale du visage
        const faceArea = detection.box.width * detection.box.height;
        if (faceArea < config.minFaceArea) {
          console.log(`‚ö†Ô∏è Visage ${i + 1} ignor√© - Trop petit: ${faceArea}px¬≤`);
          continue;
        }
        
        // V√©rifier la qualit√© des landmarks
        const landmarkQuality = this.assessLandmarkQuality(detection.landmarks);
        if (landmarkQuality < config.minLandmarkConfidence) {
          console.log(`‚ö†Ô∏è Visage ${i + 1} ignor√© - Qualit√© landmarks insuffisante: ${(landmarkQuality * 100).toFixed(1)}%`);
          continue;
        }
        
        // Calculer la qualit√© du descripteur avec des crit√®res adaptatifs
        const quality = this.calculateAdaptiveQuality(detection.descriptor, detection, imageElement);
        
        // V√©rifier le score de flou
        if (quality.blurQuality < (1 - config.maxBlurScore)) {
          console.log(`‚ö†Ô∏è Visage ${i + 1} ignor√© - Trop flou: ${(quality.blurQuality * 100).toFixed(1)}%`);
          continue;
        }
        
        // V√©rifier si le visage est suffisamment bon pour √™tre inclus
        if (quality.overallQuality >= config.minDescriptorQuality || 
            (config.enablePartialFaceDetection && quality.partialFaceQuality >= config.minVisibleLandmarks)) {
          
          const analyzedFace = {
            id: `face_${Date.now()}_${i}`,
            detection: {
              box: {
                x: detection.box.x,
                y: detection.box.y,
                width: detection.box.width,
                height: detection.box.height
              },
              score: detection.score,
              scale: detection.scale || 1.0
            },
            landmarks: {
              positions: detection.landmarks.positions.map(point => ({
              x: point.x,
              y: point.y
            })),
              quality: landmarkQuality
            },
            descriptor: Array.from(detection.descriptor),
            age: detection.age,
            gender: detection.gender,
            genderProbability: detection.genderProbability,
            expressions: detection.expressions || {},
            quality: {
              ...quality,
              landmarkQuality
            },
            metadata: {
              detectedAt: new Date(),
              processingTime: Date.now(),
              modelVersion: 'face-api.js',
              detectionMethod: detection.scale ? 'multi-scale' : 'standard',
              scale: detection.scale || 1.0
            }
          };
          
          analyzedFaces.push(analyzedFace);
          
          console.log(`‚úÖ Visage ${i + 1} analys√© - Qualit√©: ${(quality.overallQuality * 100).toFixed(1)}%, Landmarks: ${(landmarkQuality * 100).toFixed(1)}%, Taille: ${detection.box.width}x${detection.box.height}`);
        } else {
          console.log(`‚ö†Ô∏è Visage ${i + 1} ignor√© - Qualit√© trop faible: ${(quality.overallQuality * 100).toFixed(1)}%`);
        }
      }
      
      console.log(`üéØ D√©tection termin√©e: ${analyzedFaces.length} visage(s) analys√©(s) sur ${uniqueDetections.length} d√©tect√©(s)`);
      
      return analyzedFaces;
    } catch (error) {
      console.error('‚ùå Erreur lors de la d√©tection:', error);
      throw new Error(`√âchec de la d√©tection: ${error.message}`);
    }
  }

  // üéØ RECONNAISSANCE ULTRA-PR√âCISE DE VISAGES
  async recognizeFaces(referenceDescriptor, targetFaces, options = {}) {
    if (!this.isInitialized) {
      throw new Error('Moteur non initialis√©');
    }

    try {
      const config = { ...this.config, ...options };
      
      console.log('üéØ D√©but de la reconnaissance faciale ultra-pr√©cise...');
      console.log(`üìä Comparaison avec ${targetFaces.length} visage(s)`);
      
      const results = [];
      
      for (const targetFace of targetFaces) {
        if (!targetFace.descriptor || targetFace.descriptor.length === 0) {
          console.warn('‚ö†Ô∏è Visage sans descripteur, ignor√©');
          continue;
        }
        
        // V√©rifier la pr√©sence des landmarks
        if (!targetFace.landmarks || !targetFace.landmarks.positions) {
          console.warn('‚ö†Ô∏è Visage sans landmarks, utilisant uniquement le descripteur');
          // Utiliser la m√©thode de base si pas de landmarks
        const similarity = this.calculateSimilarity(referenceDescriptor, targetFace.descriptor);
          
          if (similarity >= config.similarityThreshold) {
            results.push({
              faceId: targetFace.id,
              similarity: similarity,
              confidence: similarity * 0.8, // Confiance r√©duite sans landmarks
              quality: targetFace.quality,
              metadata: {
                processingTime: Date.now(),
                method: 'descriptor_only',
                thresholds: { similarity: config.similarityThreshold }
              }
            });
          }
          continue;
        }

        // Cr√©er un objet face avec le descripteur de r√©f√©rence
        const referenceFace = {
          descriptor: referenceDescriptor,
          landmarks: targetFace.landmarks // Utiliser les landmarks de la cible pour la normalisation
        };
        
        // Calculer la similarit√© compl√®te avec landmarks
        const similarity = this.calculateSimilarityWithLandmarks(referenceFace, targetFace);
        
        // Calculer la confiance avec des seuils adaptatifs
        const confidence = this.calculateAdaptiveConfidence(similarity, targetFace.quality, config);
        
        // V√©rifier la qualit√© des landmarks
        const landmarkQuality = this.assessLandmarkQuality(targetFace.landmarks);
        
        // Seuils adaptatifs selon la qualit√©
        const adaptiveThresholds = this.calculateAdaptiveThresholds(targetFace.quality, config);
        
        // V√©rifier si la correspondance est valide avec les seuils adaptatifs
        const isValidMatch = (
          similarity >= adaptiveThresholds.similarity &&
          confidence >= adaptiveThresholds.confidence &&
          targetFace.quality.overallQuality >= adaptiveThresholds.quality &&
          landmarkQuality >= config.minLandmarkConfidence
        );
        
        if (isValidMatch) {
          const result = {
            faceId: targetFace.id,
            similarity: similarity,
            confidence: confidence,
            quality: {
              ...targetFace.quality,
              landmarkQuality: landmarkQuality
            },
            metadata: {
              processingTime: Date.now(),
              method: 'full_analysis',
              thresholds: adaptiveThresholds,
              detectionMethod: targetFace.metadata?.detectionMethod || 'standard',
              scale: targetFace.metadata?.scale || 1.0
            }
          };
          
          results.push(result);
          
          console.log(`‚úÖ Match trouv√© - Similarit√©: ${(similarity * 100).toFixed(1)}%, Confiance: ${(confidence * 100).toFixed(1)}%, Qualit√© landmarks: ${(landmarkQuality * 100).toFixed(1)}%`);
        } else {
          console.log(`‚ùå Pas de match - Similarit√©: ${(similarity * 100).toFixed(1)}%, Confiance: ${(confidence * 100).toFixed(1)}%, Qualit√© landmarks: ${(landmarkQuality * 100).toFixed(1)}%`);
        }
      }
      
      // Trier par similarit√© d√©croissante
      results.sort((a, b) => b.similarity - a.similarity);
      
      // Limiter le nombre de r√©sultats
      const finalResults = results.slice(0, config.maxResults);
      
      console.log(`üìä ${finalResults.length} correspondance(s) trouv√©e(s) sur ${results.length} comparaisons`);
      
      return finalResults;
    } catch (error) {
      console.error('‚ùå Erreur lors de la reconnaissance:', error);
      throw new Error(`√âchec de la reconnaissance: ${error.message}`);
    }
  }

  // üéØ CALCUL DE CONFIANCE ADAPTATIVE
  calculateAdaptiveConfidence(similarity, quality, config) {
    // Poids adaptatifs selon la qualit√© du visage
    const similarityWeight = 0.6;
    const qualityWeight = 0.4;
    
    // Ajuster les poids selon la qualit√©
    let adjustedSimilarityWeight = similarityWeight;
    let adjustedQualityWeight = qualityWeight;
    
    if (quality.overallQuality < 0.3) {
      // Pour les visages de faible qualit√©, donner plus de poids √† la similarit√©
      adjustedSimilarityWeight = 0.8;
      adjustedQualityWeight = 0.2;
    } else if (quality.overallQuality > 0.8) {
      // Pour les visages de haute qualit√©, √©quilibrer les poids
      adjustedSimilarityWeight = 0.5;
      adjustedQualityWeight = 0.5;
    }
    
    // Calculer la confiance de base
    const baseConfidence = (similarity * adjustedSimilarityWeight) + (quality.overallQuality * adjustedQualityWeight);
    
    // Bonus pour les petits visages bien d√©tect√©s
    let sizeBonus = 0;
    if (quality.faceRatio < 0.01 && quality.sizeQuality > 0.5) {
      sizeBonus = 0.1; // Bonus de 10% pour les petits visages de bonne qualit√©
    }
    
    // Bonus pour les visages partiels bien reconnus
    let partialBonus = 0;
    if (quality.partialFaceQuality < 0.8 && similarity > 0.7) {
      partialBonus = 0.05; // Bonus de 5% pour les visages partiels bien reconnus
    }
    
    return Math.min(1, baseConfidence + sizeBonus + partialBonus);
  }
  
  // üéØ CALCUL DE SEUILS ADAPTATIFS
  calculateAdaptiveThresholds(quality, config) {
    let similarityThreshold = config.similarityThreshold;
    let confidenceThreshold = config.confidenceThreshold;
    let qualityThreshold = config.minDescriptorQuality;
    
    // Ajuster les seuils selon la qualit√© du visage
    if (quality.overallQuality < 0.3) {
      // Visages de tr√®s faible qualit√© : seuils plus bas
      similarityThreshold *= 0.8;
      confidenceThreshold *= 0.7;
      qualityThreshold *= 0.5;
    } else if (quality.overallQuality < 0.6) {
      // Visages de qualit√© moyenne : seuils l√©g√®rement plus bas
      similarityThreshold *= 0.9;
      confidenceThreshold *= 0.85;
      qualityThreshold *= 0.8;
    } else if (quality.overallQuality > 0.8) {
      // Visages de haute qualit√© : seuils standards
      // Pas d'ajustement
    }
    
    // Ajustements sp√©ciaux pour les petits visages
    if (quality.faceRatio < 0.005) { // Tr√®s petits visages
      similarityThreshold *= 0.75;
      confidenceThreshold *= 0.6;
    } else if (quality.faceRatio < 0.01) { // Petits visages
      similarityThreshold *= 0.85;
      confidenceThreshold *= 0.75;
    }
    
    // Ajustements pour les visages partiels
    if (quality.partialFaceQuality < 0.7) {
      similarityThreshold *= 0.8;
      confidenceThreshold *= 0.7;
    }
    
    return {
      similarity: Math.max(0.2, similarityThreshold),
      confidence: Math.max(0.2, confidenceThreshold),
      quality: Math.max(0.1, qualityThreshold)
    };
  }

  // üîç RECHERCHE DE VISAGES SIMILAIRES
  async findSimilarFaces(referenceDescriptor, photos, options = {}) {
    if (!this.isInitialized) {
      throw new Error('Moteur non initialis√©');
    }

    try {
      const config = { ...this.config, ...options };
      
      console.log('üîç Recherche de visages similaires...');
      console.log(`üìä Analyse de ${photos.length} photos`);
      
      const results = [];
      let processedPhotos = 0;
      let analyzedFaces = 0;
      
      for (const photo of photos) {
        processedPhotos++;
        
        // V√©rifier si la photo a d√©j√† √©t√© analys√©e
        if (photo.faceAnalysis && photo.faceAnalysis.faces && photo.faceAnalysis.faces.length > 0) {
          analyzedFaces += photo.faceAnalysis.faces.length;
          
          // Comparer avec chaque visage d√©tect√©
          const recognitions = await this.recognizeFaces(
            referenceDescriptor, 
            photo.faceAnalysis.faces,
            config
          );
          
          // Ajouter les r√©sultats avec les m√©tadonn√©es de la photo
          for (const recognition of recognitions) {
            results.push({
              photoId: photo.id,
              fileName: photo.fileName,
              path: photo.path || photo.url,
              faceId: recognition.faceId,
              similarity: recognition.similarity,
              confidence: recognition.confidence,
              quality: recognition.quality,
              metadata: {
                ...recognition.metadata,
                photoInfo: {
                  id: photo.id,
                  fileName: photo.fileName,
                  processedAt: photo.faceAnalysis.processedAt
                }
              }
            });
          }
        } else {
          console.log(`‚ö†Ô∏è Photo ${photo.fileName} non analys√©e`);
        }
      }
      
      // Trier par similarit√© d√©croissante
      results.sort((a, b) => b.similarity - a.similarity);
      
      // Limiter le nombre de r√©sultats
      const limitedResults = results.slice(0, config.maxResults);
      
      console.log(`‚úÖ Recherche termin√©e: ${limitedResults.length} r√©sultat(s) trouv√©(s)`);
      console.log(`üìä Photos trait√©es: ${processedPhotos}, Visages analys√©s: ${analyzedFaces}`);
      
      return limitedResults;
    } catch (error) {
      console.error('‚ùå Erreur lors de la recherche:', error);
      throw new Error(`√âchec de la recherche: ${error.message}`);
    }
  }

  // üìä CALCULS DE SIMILARIT√â ET CONFIANCE
  calculateSimilarity(descriptor1, descriptor2) {
    if (!descriptor1 || !descriptor2 || descriptor1.length !== descriptor2.length) {
      return 0;
    }
    
    // Distance euclidienne normalis√©e pour les descripteurs
    let descriptorDistance = 0;
    for (let i = 0; i < descriptor1.length; i++) {
      descriptorDistance += Math.pow(descriptor1[i] - descriptor2[i], 2);
    }
    descriptorDistance = Math.sqrt(descriptorDistance);
    
    // Convertir en similarit√© (0 = tr√®s diff√©rent, 1 = identique)
    const descriptorSimilarity = Math.max(0, 1 - (descriptorDistance / Math.sqrt(descriptor1.length)));
    
    return descriptorSimilarity;
  }

  // Nouvelle fonction pour calculer la similarit√© avec landmarks
  calculateSimilarityWithLandmarks(face1, face2) {
    // V√©rifier la pr√©sence des donn√©es n√©cessaires
    if (!face1 || !face2 || !face1.descriptor || !face2.descriptor || 
        !face1.landmarks || !face2.landmarks) {
      return 0;
    }

    // Similarit√© des descripteurs
    const descriptorSimilarity = this.calculateSimilarity(face1.descriptor, face2.descriptor);

    // Similarit√© des landmarks
    const landmarkSimilarity = this.calculateLandmarkSimilarity(face1.landmarks, face2.landmarks);

    // Similarit√© de la g√©om√©trie du visage
    const geometrySimilarity = this.calculateGeometrySimilarity(face1.landmarks, face2.landmarks);

    // Pond√©ration des diff√©rentes similarit√©s
    const weights = {
      descriptor: 0.6,  // Le descripteur reste le plus important
      landmarks: 0.25,  // Les landmarks ont un poids significatif
      geometry: 0.15    // La g√©om√©trie compl√®te l'analyse
    };

    // Calcul de la similarit√© finale pond√©r√©e
    const finalSimilarity = (
      descriptorSimilarity * weights.descriptor +
      landmarkSimilarity * weights.landmarks +
      geometrySimilarity * weights.geometry
    );

    return Math.max(0, Math.min(1, finalSimilarity));
  }

  // Calcul de la similarit√© des landmarks
  calculateLandmarkSimilarity(landmarks1, landmarks2) {
    if (!landmarks1.positions || !landmarks2.positions || 
        landmarks1.positions.length !== landmarks2.positions.length) {
      return 0;
    }

    let totalDistance = 0;
    const positions1 = landmarks1.positions;
    const positions2 = landmarks2.positions;

    // Normaliser les positions par rapport au centre du visage
    const center1 = this.calculateLandmarkCenter(positions1);
    const center2 = this.calculateLandmarkCenter(positions2);

    for (let i = 0; i < positions1.length; i++) {
      const dx1 = positions1[i].x - center1.x;
      const dy1 = positions1[i].y - center1.y;
      const dx2 = positions2[i].x - center2.x;
      const dy2 = positions2[i].y - center2.y;

      // Distance euclidienne normalis√©e
      totalDistance += Math.sqrt(
        Math.pow(dx1 - dx2, 2) + Math.pow(dy1 - dy2, 2)
      );
    }

    // Convertir en similarit√© (0 = tr√®s diff√©rent, 1 = identique)
    const avgDistance = totalDistance / positions1.length;
    return Math.max(0, 1 - (avgDistance / 100)); // 100 est un facteur de normalisation
  }

  // Calcul de la similarit√© g√©om√©trique
  calculateGeometrySimilarity(landmarks1, landmarks2) {
    if (!landmarks1.positions || !landmarks2.positions) return 0;

    // Points cl√©s pour la g√©om√©trie du visage
    const keyPoints = {
      eyeLeft: [36, 37, 38, 39, 40, 41],
      eyeRight: [42, 43, 44, 45, 46, 47],
      nose: [27, 28, 29, 30, 31, 32, 33, 34, 35],
      mouth: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]
    };

    let similarities = [];

    // Calculer les ratios de distance pour chaque paire de points cl√©s
    for (const [feature1, indices1] of Object.entries(keyPoints)) {
      for (const [feature2, indices2] of Object.entries(keyPoints)) {
        if (feature1 !== feature2) {
          const ratio1 = this.calculateFeatureDistance(landmarks1.positions, indices1, indices2);
          const ratio2 = this.calculateFeatureDistance(landmarks2.positions, indices1, indices2);
          
          const ratioDiff = Math.abs(ratio1 - ratio2);
          similarities.push(Math.max(0, 1 - ratioDiff));
        }
      }
    }

    // Moyenne des similarit√©s
    return similarities.reduce((a, b) => a + b, 0) / similarities.length;
  }

  // Calcul du centre des landmarks
  calculateLandmarkCenter(positions) {
    const sum = positions.reduce((acc, pos) => ({
      x: acc.x + pos.x,
      y: acc.y + pos.y
    }), { x: 0, y: 0 });
    
    return {
      x: sum.x / positions.length,
      y: sum.y / positions.length
    };
  }

  // Calcul de la distance entre deux groupes de points caract√©ristiques
  calculateFeatureDistance(positions, indices1, indices2) {
    const center1 = this.calculateLandmarkCenter(
      indices1.map(i => positions[i])
    );
    const center2 = this.calculateLandmarkCenter(
      indices2.map(i => positions[i])
    );

    return Math.sqrt(
      Math.pow(center1.x - center2.x, 2) + 
      Math.pow(center1.y - center2.y, 2)
    );
  }

  calculateDescriptorQuality(descriptor, detection) {
    if (!descriptor || descriptor.length === 0) {
      return 0;
    }
    
    // Calculer la variance du descripteur
    const mean = descriptor.reduce((sum, val) => sum + val, 0) / descriptor.length;
    const variance = descriptor.reduce((sum, val) => sum + Math.pow(val - mean, 2), 0) / descriptor.length;
    
    // Qualit√© bas√©e sur la variance et la confiance de d√©tection
    const varianceQuality = Math.min(1, Math.sqrt(variance) * 2);
    const detectionQuality = detection.score;
    
    return (varianceQuality * 0.7) + (detectionQuality * 0.3);
  }

  calculateOverallQuality(detection, descriptorQuality, imageElement) {
    const detectionQuality = detection.score;
    const sizeQuality = Math.min(1, (detection.box.width * detection.box.height) / 10000);
    const resolutionQuality = this.assessImageResolution(imageElement);
    
    return (
      detectionQuality * 0.4 +
      descriptorQuality * 0.3 +
      sizeQuality * 0.2 +
      resolutionQuality * 0.1
    );
  }

  assessImageResolution(imageElement) {
    const width = imageElement.naturalWidth || imageElement.width;
    const height = imageElement.naturalHeight || imageElement.height;
    
    const totalPixels = width * height;
    
    if (totalPixels >= 2000000) return 1.0; // 2MP+
    if (totalPixels >= 1000000) return 0.8; // 1MP+
    if (totalPixels >= 500000) return 0.6;  // 0.5MP+
    if (totalPixels >= 250000) return 0.4;  // 0.25MP+
    return 0.2; // Tr√®s faible r√©solution
  }

  // ‚öôÔ∏è CONFIGURATION
  updateConfig(newConfig) {
    this.config = { ...this.config, ...newConfig };
    console.log('‚öôÔ∏è Configuration mise √† jour:', this.config);
  }

  getConfig() {
    return { ...this.config };
  }

  // üìä STATUT ET INFORMATIONS
  getStatus() {
    return {
      isInitialized: this.isInitialized,
      modelsLoaded: this.modelsLoaded,
      isReady: this.isInitialized && this.modelsLoaded,
      config: this.getConfig(),
      cacheSize: this.descriptorCache.size
    };
  }

  // üßπ NETTOYAGE
  clearCache() {
    this.descriptorCache.clear();
    this.analysisCache.clear();
    console.log('üßπ Cache vid√©');
  }

  // üßπ SUPPRESSION DES DOUBLONS DE D√âTECTION
  removeDuplicateDetections(detections) {
    if (detections.length <= 1) return detections;
    
    const uniqueDetections = [];
    const overlapThreshold = 0.7; // Seuil de chevauchement pour consid√©rer comme doublon
    
    for (const detection of detections) {
      let isDuplicate = false;
      
      for (const uniqueDetection of uniqueDetections) {
        const overlap = this.calculateOverlap(detection.box, uniqueDetection.box);
        
        if (overlap > overlapThreshold) {
          // Garder la d√©tection avec le meilleur score
          if (detection.score > uniqueDetection.score) {
            const index = uniqueDetections.indexOf(uniqueDetection);
            uniqueDetections[index] = detection;
          }
          isDuplicate = true;
          break;
        }
      }
      
      if (!isDuplicate) {
        uniqueDetections.push(detection);
      }
    }
    
    return uniqueDetections;
  }
  
  // üìê CALCUL DU CHEVAUCHEMENT ENTRE DEUX BO√éTES
  calculateOverlap(box1, box2) {
    const x1 = Math.max(box1.x, box2.x);
    const y1 = Math.max(box1.y, box2.y);
    const x2 = Math.min(box1.x + box1.width, box2.x + box2.width);
    const y2 = Math.min(box1.y + box1.height, box2.y + box2.height);
    
    if (x2 <= x1 || y2 <= y1) return 0;
    
    const intersection = (x2 - x1) * (y2 - y1);
    const area1 = box1.width * box1.height;
    const area2 = box2.width * box2.height;
    const union = area1 + area2 - intersection;
    
    return intersection / union;
  }
  
  // üéØ CALCUL DE QUALIT√â ADAPTATIVE
  calculateAdaptiveQuality(descriptor, detection, imageElement) {
    if (!descriptor || descriptor.length === 0) {
      return {
        descriptorQuality: 0,
        faceSize: 0,
        confidence: 0,
        resolution: 0,
        overallQuality: 0,
        sizeQuality: 0,
        blurQuality: 1,
        partialFaceQuality: 1
      };
    }
    
    // Qualit√© du descripteur
    const descriptorQuality = this.calculateDescriptorQuality(descriptor, detection);
    
    // Qualit√© de la taille du visage (adaptative)
    const faceArea = detection.box.width * detection.box.height;
    const imageArea = (imageElement.naturalWidth || imageElement.width) * (imageElement.naturalHeight || imageElement.height);
    const faceRatio = faceArea / imageArea;
    
    // Qualit√© adaptative selon la taille
    let sizeQuality;
    if (faceRatio > 0.01) { // Visage > 1% de l'image
      sizeQuality = Math.min(1, faceRatio * 100);
    } else if (faceRatio > 0.001) { // Visage > 0.1% de l'image
      sizeQuality = Math.min(0.8, faceRatio * 800);
    } else { // Tr√®s petit visage
      sizeQuality = Math.min(0.6, faceRatio * 6000);
    }
    
    // Qualit√© de la r√©solution
    const resolutionQuality = this.assessImageResolution(imageElement);
    
    // Qualit√© de la confiance de d√©tection
    const confidenceQuality = detection.score;
    
    // Qualit√© du flou (estimation bas√©e sur la variance des landmarks)
    const blurQuality = this.assessBlurQuality(detection.landmarks);
    
    // Qualit√© des visages partiels
    const partialFaceQuality = this.assessPartialFaceQuality(detection.landmarks, detection.box);
    
    // Qualit√© globale adaptative
    const overallQuality = (
      descriptorQuality * 0.25 +
      sizeQuality * 0.20 +
      confidenceQuality * 0.20 +
      resolutionQuality * 0.15 +
      blurQuality * 0.10 +
      partialFaceQuality * 0.10
    );
    
    return {
      descriptorQuality,
      faceSize: faceArea,
      confidence: detection.score,
      resolution: resolutionQuality,
      overallQuality,
      sizeQuality,
      blurQuality,
      partialFaceQuality,
      faceRatio
    };
  }
  
  // üîç √âVALUATION DE LA QUALIT√â DU FLOU
  assessBlurQuality(landmarks) {
    if (!landmarks || !landmarks.positions || landmarks.positions.length < 10) {
      return 0.5; // Qualit√© moyenne par d√©faut
    }
    
    // Calculer la variance des positions des landmarks
    const positions = landmarks.positions;
    const centerX = positions.reduce((sum, pos) => sum + pos.x, 0) / positions.length;
    const centerY = positions.reduce((sum, pos) => sum + pos.y, 0) / positions.length;
    
    const variance = positions.reduce((sum, pos) => {
      const dx = pos.x - centerX;
      const dy = pos.y - centerY;
      return sum + (dx * dx + dy * dy);
    }, 0) / positions.length;
    
    // Plus la variance est √©lev√©e, plus l'image est floue
    const blurScore = Math.min(1, Math.sqrt(variance) / 100);
    return Math.max(0.1, 1 - blurScore);
  }
  
  // üé≠ √âVALUATION DE LA QUALIT√â DES VISAGES PARTIELS
  assessPartialFaceQuality(landmarks, box) {
    if (!landmarks || !landmarks.positions) {
      return 0.5;
    }
    
    const positions = landmarks.positions;
    const boxArea = box.width * box.height;
    
    // Compter les landmarks visibles (dans la bo√Æte)
    let visibleLandmarks = 0;
    for (const pos of positions) {
      if (pos.x >= box.x && pos.x <= box.x + box.width &&
          pos.y >= box.y && pos.y <= box.y + box.height) {
        visibleLandmarks++;
      }
    }
    
    const visibilityRatio = visibleLandmarks / positions.length;
    
    // Qualit√© bas√©e sur la visibilit√© des landmarks
    if (visibilityRatio >= 0.9) return 1.0; // Visage complet
    if (visibilityRatio >= 0.7) return 0.8; // Visage presque complet
    if (visibilityRatio >= 0.5) return 0.6; // Visage partiel
    if (visibilityRatio >= 0.3) return 0.4; // Visage tr√®s partiel
    return 0.2; // Visage tr√®s incomplet
  }

  // üîç RECHERCHE RAPIDE DANS L'INDEX GLOBAL
  async searchInIndex(referenceImg) {
    // Extraire le descripteur du visage de r√©f√©rence
    const analyzedFaces = await this.detectFaces(referenceImg);
    if (!analyzedFaces || analyzedFaces.length === 0) {
      throw new Error('Aucun visage d√©tect√© dans l\'image de r√©f√©rence');
    }
    const referenceDescriptor = analyzedFaces[0].descriptor;
    // Recherche rapide dans l'index via IPC
    const results = await window.electronAPI.searchFaceIndex(referenceDescriptor, 5);
    return results;
  }

  // Nouvelle fonction pour √©valuer la qualit√© des landmarks
  assessLandmarkQuality(landmarks) {
    if (!landmarks || !landmarks.positions || landmarks.positions.length === 0) {
      return 0;
    }

    // V√©rifier la pr√©sence de tous les points cl√©s
    const keyPoints = {
      eyeLeft: [36, 37, 38, 39, 40, 41],
      eyeRight: [42, 43, 44, 45, 46, 47],
      nose: [27, 28, 29, 30, 31, 32, 33, 34, 35],
      mouth: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59],
      jawline: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
    };

    let qualityScores = [];

    // V√©rifier chaque groupe de points
    for (const [feature, indices] of Object.entries(keyPoints)) {
      let validPoints = 0;
      for (const idx of indices) {
        if (landmarks.positions[idx] && 
            landmarks.positions[idx].x !== undefined && 
            landmarks.positions[idx].y !== undefined) {
          validPoints++;
        }
      }
      const featureQuality = validPoints / indices.length;
      qualityScores.push(featureQuality);
    }

    // Calculer la qualit√© moyenne
    const avgQuality = qualityScores.reduce((a, b) => a + b, 0) / qualityScores.length;

    // P√©naliser si certaines caract√©ristiques sont manquantes
    const minFeatureQuality = Math.min(...qualityScores);
    
    return Math.min(avgQuality, minFeatureQuality * 1.2);
  }
}

// Instance singleton
const faceRecognitionEngine = new FaceRecognitionEngine();
export default faceRecognitionEngine; 